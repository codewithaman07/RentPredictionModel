{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the test and train csv files\n",
    "train_data = pd.read_csv(\"Data/train.csv\")\n",
    "test_data = pd.read_csv(\"Data/test.csv\")\n",
    "x = train_data.drop(\"price\", axis=1)\n",
    "y= train_data['price']\n",
    "x1= test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['AGENT', 'BHK', 'Independent Floor', ..., '3 bathrooms', 1900.0,\n",
       "        3.0],\n",
       "       ['AGENT', 'BHK', 'Independent Floor', ..., '5 bathrooms', 6521.0,\n",
       "        5.0],\n",
       "       ['OWNER', 'BHK', 'Independent House', ..., '1 bathrooms', 450.0,\n",
       "        1.0],\n",
       "       ...,\n",
       "       ['AGENT', 'BHK', 'Independent House', ..., '3 bathrooms', 1700.0,\n",
       "        3.0],\n",
       "       ['AGENT', 'BHK', 'Independent Floor', ..., '4 bathrooms', 3251.0,\n",
       "        4.0],\n",
       "       ['AGENT', 'BHK', 'Independent Floor', ..., '2 bathrooms', 720.0,\n",
       "        2.0]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# filling categorical values with missing and numerical value with mean\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value=\"missing\")\n",
    "num_imputer = SimpleImputer(fill_value=\"mean\")\n",
    "num2_imputer = SimpleImputer(fill_value = \"mean\")\n",
    "\n",
    "#define columns\n",
    "cat_features = ['seller_type','layout_type','property_type','locality','furnish_type','bathroom']\n",
    "num_features = ['area']\n",
    "num2_features = ['bedroom']\n",
    "\n",
    "# CREATE an imputer (something that fill missing data)\n",
    "imputer = ColumnTransformer([('cat_imputer', cat_imputer, cat_features),('num_imputer',num_imputer,num_features),('num2_imputer',num2_imputer,num2_features)])\n",
    "\n",
    "# Transform the data \n",
    "filled_x = imputer.fit_transform(x)\n",
    "filled_x\n",
    "\n",
    "filled_x1 = imputer.fit_transform(x1)\n",
    "filled_x1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_type</th>\n",
       "      <th>layout_type</th>\n",
       "      <th>property_type</th>\n",
       "      <th>locality</th>\n",
       "      <th>furnish_type</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>area</th>\n",
       "      <th>bedroom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGENT</td>\n",
       "      <td>BHK</td>\n",
       "      <td>Independent Floor</td>\n",
       "      <td>Safdarjung Enclave</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>3 bathrooms</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGENT</td>\n",
       "      <td>BHK</td>\n",
       "      <td>Independent Floor</td>\n",
       "      <td>Greater Kailash II</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>5 bathrooms</td>\n",
       "      <td>6521.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OWNER</td>\n",
       "      <td>BHK</td>\n",
       "      <td>Independent House</td>\n",
       "      <td>Jhil Mil Colony</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>1 bathrooms</td>\n",
       "      <td>450.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGENT</td>\n",
       "      <td>BHK</td>\n",
       "      <td>Independent Floor</td>\n",
       "      <td>Greater Kailash</td>\n",
       "      <td>Furnished</td>\n",
       "      <td>1 bathrooms</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGENT</td>\n",
       "      <td>BHK</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Sector 10 Dwarka</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>2 bathrooms</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seller_type layout_type      property_type            locality  \\\n",
       "0       AGENT         BHK  Independent Floor  Safdarjung Enclave   \n",
       "1       AGENT         BHK  Independent Floor  Greater Kailash II   \n",
       "2       OWNER         BHK  Independent House     Jhil Mil Colony   \n",
       "3       AGENT         BHK  Independent Floor     Greater Kailash   \n",
       "4       AGENT         BHK          Apartment    Sector 10 Dwarka   \n",
       "\n",
       "     furnish_type     bathroom    area bedroom  \n",
       "0  Semi-Furnished  3 bathrooms  1900.0     3.0  \n",
       "1     Unfurnished  5 bathrooms  6521.0     5.0  \n",
       "2     Unfurnished  1 bathrooms   450.0     1.0  \n",
       "3       Furnished  1 bathrooms  1000.0     1.0  \n",
       "4  Semi-Furnished  2 bathrooms  1600.0     3.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the dataframe after filling values in x and x1\n",
    "train_data_filled = pd.DataFrame(filled_x, columns=['seller_type','layout_type','property_type','locality','furnish_type','bathroom','area','bedroom'])\n",
    "test_data_filled = pd.DataFrame(filled_x1, columns=['seller_type','layout_type','property_type','locality','furnish_type','bathroom','area','bedroom'])\n",
    "test_data_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Train Data:\n",
      "  (0, 0)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (0, 95)\t1.0\n",
      "  (0, 679)\t1.0\n",
      "  (0, 681)\t1.0\n",
      "  (0, 712)\t500.0\n",
      "  (0, 713)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 7)\t1.0\n",
      "  (1, 627)\t1.0\n",
      "  (1, 677)\t1.0\n",
      "  (1, 688)\t1.0\n",
      "  (1, 712)\t581.0\n",
      "  (1, 713)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (2, 8)\t1.0\n",
      "  (2, 302)\t1.0\n",
      "  (2, 677)\t1.0\n",
      "  (2, 681)\t1.0\n",
      "  (2, 712)\t500.0\n",
      "  (2, 713)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  :\t:\n",
      "  (29696, 713)\t4.0\n",
      "  (29697, 0)\t1.0\n",
      "  (29697, 4)\t1.0\n",
      "  (29697, 7)\t1.0\n",
      "  (29697, 471)\t1.0\n",
      "  (29697, 678)\t1.0\n",
      "  (29697, 688)\t1.0\n",
      "  (29697, 712)\t1500.0\n",
      "  (29697, 713)\t3.0\n",
      "  (29698, 0)\t1.0\n",
      "  (29698, 4)\t1.0\n",
      "  (29698, 8)\t1.0\n",
      "  (29698, 630)\t1.0\n",
      "  (29698, 678)\t1.0\n",
      "  (29698, 696)\t1.0\n",
      "  (29698, 712)\t5400.0\n",
      "  (29698, 713)\t4.0\n",
      "  (29699, 0)\t1.0\n",
      "  (29699, 4)\t1.0\n",
      "  (29699, 9)\t1.0\n",
      "  (29699, 460)\t1.0\n",
      "  (29699, 678)\t1.0\n",
      "  (29699, 688)\t1.0\n",
      "  (29699, 712)\t1150.0\n",
      "  (29699, 713)\t2.0\n",
      "\n",
      "Transformed Test Data:\n",
      "  (0, 0)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (0, 453)\t1.0\n",
      "  (0, 678)\t1.0\n",
      "  (0, 692)\t1.0\n",
      "  (0, 712)\t1900.0\n",
      "  (0, 713)\t3.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 8)\t1.0\n",
      "  (1, 180)\t1.0\n",
      "  (1, 679)\t1.0\n",
      "  (1, 698)\t1.0\n",
      "  (1, 712)\t6521.0\n",
      "  (1, 713)\t5.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (2, 9)\t1.0\n",
      "  (2, 229)\t1.0\n",
      "  (2, 679)\t1.0\n",
      "  (2, 681)\t1.0\n",
      "  (2, 712)\t450.0\n",
      "  (2, 713)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  :\t:\n",
      "  (3296, 713)\t1.0\n",
      "  (3297, 0)\t1.0\n",
      "  (3297, 4)\t1.0\n",
      "  (3297, 9)\t1.0\n",
      "  (3297, 460)\t1.0\n",
      "  (3297, 678)\t1.0\n",
      "  (3297, 692)\t1.0\n",
      "  (3297, 712)\t1700.0\n",
      "  (3297, 713)\t3.0\n",
      "  (3298, 0)\t1.0\n",
      "  (3298, 4)\t1.0\n",
      "  (3298, 8)\t1.0\n",
      "  (3298, 156)\t1.0\n",
      "  (3298, 679)\t1.0\n",
      "  (3298, 696)\t1.0\n",
      "  (3298, 712)\t3251.0\n",
      "  (3298, 713)\t4.0\n",
      "  (3299, 0)\t1.0\n",
      "  (3299, 4)\t1.0\n",
      "  (3299, 8)\t1.0\n",
      "  (3299, 135)\t1.0\n",
      "  (3299, 677)\t1.0\n",
      "  (3299, 688)\t1.0\n",
      "  (3299, 712)\t720.0\n",
      "  (3299, 713)\t2.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combining train and test data so we can encode it using one hot encoder so no feature error will occur\n",
    "combined_data = pd.concat([train_data_filled, test_data_filled], ignore_index=True)\n",
    "\n",
    "# Define categorical features\n",
    "categorical_features = [\"seller_type\", \"layout_type\", \"property_type\", \"locality\", \"furnish_type\", \"bathroom\"]\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# Initialize ColumnTransformer\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "\n",
    "# Fit and transform the combined data\n",
    "transformed_combined_data = transformer.fit_transform(combined_data)\n",
    "\n",
    "# Split the transformed data back into train and test sets\n",
    "transformed_train_data = transformed_combined_data[:len(train_data_filled)]\n",
    "transformed_test_data = transformed_combined_data[len(train_data_filled):]\n",
    "\n",
    "# Print the transformed data for reference\n",
    "print(\"Transformed Train Data:\")\n",
    "print(transformed_train_data)\n",
    "\n",
    "print(\"\\nTransformed Test Data:\")\n",
    "print(transformed_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9020297058404751"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Splitting the transformed_train_data to analyse the accuracy of the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(transformed_train_data, y, test_size=0.2)\n",
    "\n",
    "# TRAINING THE MODEL\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# score of the model\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(transformed_test_data)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "output_df = pd.DataFrame({'Predictions': predictions})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
